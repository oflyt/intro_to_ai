{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT=100\n",
    "IMG_WIDTH=100\n",
    "\n",
    "epsilon = 1\n",
    "gamma = 0.99\n",
    "n_episodes = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "\n",
    "def show_state(observation, env_id, step=0, info=\"\"):\n",
    "    plt.figure(3)\n",
    "    plt.clf()\n",
    "    plt.imshow(observation, cmap='gray')\n",
    "    plt.title(\"%s | Step: %d %s\" % (env_id, step, info))\n",
    "    plt.axis('off')\n",
    "    \n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def downsize(img_arry):\n",
    "    return cv2.resize(img_arry, dsize=(IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "def rgb2gray(img_arr):\n",
    "    return np.dot(img_arr[...,:3], [0.299, 0.587, 0.114])\n",
    "\n",
    "def normalize(img_arr):\n",
    "    return np.divide(img_arr, 255.0)\n",
    "\n",
    "def preprocess_image(img_arr):\n",
    "    downsized = downsize(img_arr)\n",
    "    gray = rgb2gray(downsized)\n",
    "    normalized = normalize(gray)\n",
    "    extra_dim = normalized[..., np.newaxis]\n",
    "    for i in range(2):\n",
    "        extra_dim = np.append(extra_dim, extra_dim, axis=2)\n",
    "    return np.stack(extra_dim)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Memory:\n",
    "\n",
    "    # wants the following input\n",
    "    # [(state, action, reward, next_state, done)...]\n",
    "    def __init__(self):\n",
    "        self.memory = np.zeros(shape=(0, 5))\n",
    "\n",
    "    # @params\n",
    "    # state = previous 4 images\n",
    "    # action = what action we took\n",
    "    # reward = reward\n",
    "    # next_state = what happened\n",
    "    # done = done\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        new_row = np.array([[state, action, reward, next_state, done]])\n",
    "        self.memory = np.append(self.memory, new_row, axis=0)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        #return np.random.choice(self.memory, size=batch_size, replace=False)\n",
    "        return self.memory[np.random.choice(self.memory.shape[0], batch_size, replace=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.core import Flatten\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "\n",
    "def atari_model(state_shape, n_actions):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16,\n",
    "        kernel_size=(4, 4),\n",
    "        strides=(2, 2),\n",
    "        activation=\"relu\",\n",
    "        input_shape=state_shape))\n",
    "    \n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(32,\n",
    "        kernel_size=(4, 4),\n",
    "        strides=(2, 2),\n",
    "        activation=\"relu\"))\n",
    "    \n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation=\"relu\"))\n",
    "    model.add(Dense(n_actions))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def stack(array):\n",
    "    stacked_array = np.stack(array[0])\n",
    "    for i in range(1, array.shape[0]):\n",
    "        stacked_array = np.append(stacked_array, np.stack(array[i]), axis=0)\n",
    "    return stacked_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(batch, gamma):\n",
    "    states, actions, rewards, next_states, done = np.hsplit(batch, batch.shape[1])\n",
    "    \n",
    "    states = stack(states)\n",
    "    next_states = stack(next_states)\n",
    "    actions = stack(actions) # TODO: Needs one hot encoding\n",
    "    \n",
    "    next_Q_values = model.predict(np.stack(next_states))\n",
    "    Q_values = rewards + gamma * np.max(next_Q_values, axis=1)\n",
    "    \n",
    "    model.fit(\n",
    "        states, \n",
    "        actions * Q_values[:, None],\n",
    "        epochs=1, \n",
    "        batch_size=len(states), \n",
    "        verbose=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3]\n",
      " [0]\n",
      " [2]\n",
      " [3]\n",
      " [1]\n",
      " [3]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [3]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [3]\n",
      " [3]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [3]\n",
      " [2]\n",
      " [3]]\n",
      "(32,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_12 to have 2 dimensions, but got array with shape (32, 1, 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-1f7fc2585a91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Finished\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-5dabe312d1fe>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(batch, gamma)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     )\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\intro_ai\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\intro_ai\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\intro_ai\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    126\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    129\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_12 to have 2 dimensions, but got array with shape (32, 1, 32)"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make(\"BreakoutDeterministic-v4\")\n",
    "\n",
    "state_shape = (IMG_WIDTH, IMG_HEIGHT, 4)\n",
    "n_actions = env.action_space.n\n",
    "model = atari_model(state_shape, n_actions)\n",
    "done = False\n",
    "\n",
    "for episode in range(n_episodes):\n",
    "    state = env.reset()\n",
    "    memory = Memory()\n",
    "    current_state, _, _, _ = env.step(env.action_space.sample())\n",
    "    current_state = preprocess_image(current_state)\n",
    "    \n",
    "    # Fill memory\n",
    "    for t in range(32):\n",
    "        action = env.action_space.sample()\n",
    "        next_state_raw, reward, done, _ = env.step(action)\n",
    "        next_state = preprocess_image(next_state_raw)\n",
    "        memory.add(current_state, action, reward, next_state, done)\n",
    "        current_state = next_state\n",
    "\n",
    "    while not done:\n",
    "        frame = preprocess_image(env.render(mode='rgb_array'))\n",
    "        #show_state(frame, env.spec.id, t)\n",
    "\n",
    "        if random.random() < epsilon:\n",
    "            action = env.action_space.sample() \n",
    "        else:\n",
    "            # TODO: Select optimal actions\n",
    "            action = env.action_space.sample()\n",
    "\n",
    "        next_state_raw, reward, done, info = env.step(action)\n",
    "        next_state = preprocess_image(next_state_raw)\n",
    "        memory.add(current_state, action, reward, next_state, done)\n",
    "        current_state = next_state\n",
    "        \n",
    "        batch = memory.sample(32)\n",
    "        fit(batch, gamma)\n",
    "            \n",
    "    print(\"Finished\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
